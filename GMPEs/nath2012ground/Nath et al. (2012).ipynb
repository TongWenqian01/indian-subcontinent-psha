{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nath et al. (2009)\n",
    "\n",
    "In which the GMPE of Nath et al. (2009) is implemented. First coefficient tables are reprocessed for cut & paste in to the .py source code. Then, key figures in the original paper are reproduced for validation. Finally, test vectors are produced for automatic code verification using unittest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "#import toolbox as tb\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from scipy.constants import g\n",
    "import importlib\n",
    "\n",
    "from openquake.hazardlib import geo, mfd, tom, pmf, imt, const, gsim, tests\n",
    "import openquake.hazardlib.source as src\n",
    "import openquake.hazardlib.scalerel as msr\n",
    "import openquake.hazardlib.site as sit\n",
    "\n",
    "from openquake.hazardlib.gsim.sharma_2009 import SharmaEtAl2009\n",
    "\n",
    "for item in gsim.get_available_gsims().values():\n",
    "    importlib.import_module(item.__module__, item.__name__)\n",
    "    try:\n",
    "        importlib.import_module(item.__module__.replace('.gsim','.tests.gsim') + '_test', item.__name__ + 'TestCase')\n",
    "        #print 'imported', item.__name__ + 'TestCase'\n",
    "    except ImportError:\n",
    "        #print 'from', item.__module__.replace('.gsim','.tests.gsim') + '_test', 'import', item.__name__ + 'TestCase failed ...'\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coeffs = pd.DataFrame.from_csv('Tables/Table2.csv', index_col=None)\n",
    "df_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coeffs2 = pd.DataFrame.from_csv('sharma coefficients.csv', index_col=None)\n",
    "df_coeffs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how peculiar that there is just one repeated row (except for sigma) ...\n",
    "# no mention of coefficients being reused for 0.1 and 0.2 s in the paper ...\n",
    "df_coeffs2.diff() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients = ['b%d' for i in range(1,7)]\n",
    "df_coeffs.plot(x='T', y=['b1', 'b2', 'b3', 'b5', 'b6'], figsize=(6, 8), grid=True)\n",
    "plt.axhspan(-0.1, 0.1, color='0.5', alpha=0.5)\n",
    "plt.savefig('Sharma_coefficients.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Table2.txt','w') as f:\n",
    "    f.write(df_coeffs[['T', 'b1', 'b2', 'b3', 'b5', 'b6', 'sigma']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "gmpe = SharmaEtAl2009()\n",
    "print(type(gmpe).__name__)\n",
    "print('Supported tectonic region: %s' \n",
    "      % gmpe.DEFINED_FOR_TECTONIC_REGION_TYPE)\n",
    "print('Supported intensity measure types: %s' \n",
    "      % ', '.join([item.__name__ for item \n",
    "                   in gmpe.DEFINED_FOR_INTENSITY_MEASURE_TYPES]))\n",
    "print('Supported component: %s' \n",
    "      % gmpe.DEFINED_FOR_INTENSITY_MEASURE_COMPONENT)\n",
    "print('Supported standard deviations: %s' \n",
    "      % ', '.join([item for item              \n",
    "                   in gmpe.DEFINED_FOR_STANDARD_DEVIATION_TYPES]))\n",
    "print('Required site parameters: %s' \n",
    "      % ', '.join([item for item in gmpe.REQUIRES_SITES_PARAMETERS]))\n",
    "print('Required rupture parameters: %s' \n",
    "      % ', '.join([item for item in gmpe.REQUIRES_RUPTURE_PARAMETERS]))\n",
    "print('Required distance parameters: %s' \n",
    "      % ', '.join([item for item in gmpe.REQUIRES_DISTANCES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def summarize(obj):\n",
    "    print '\\n'.join(\"%s: %s\" % (item, getattr(obj, item))\n",
    "                    for item in dir(obj) if item[0] != '_')\n",
    "    \n",
    "def isnumeric(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "tectonic_region_type = 'Active Shallow Crust'\n",
    "hypo_lon = 0 # degrees\n",
    "hypo_lat = 0 # degrees\n",
    "hypo_depth = 12.5 # km\n",
    "uncertainty_types = [const.StdDev.TOTAL]\n",
    "\n",
    "# set things up so that Rjb is epicentral distance\n",
    "site_azimuth = 0 # degrees\n",
    "hypo_strike = 90 # degrees\n",
    "hypo_dip = 90 # degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_gmpe_overcomplicated(gmpe, mags, rakes, distances, vs30s, im_types):\n",
    "    \n",
    "    # set up sources\n",
    "    mechanisms = [geo.NodalPlane(strike=hypo_strike, \n",
    "                                 dip=hypo_dip, rake=rake) \n",
    "                  for rake in rakes]\n",
    "    prob = 1./len(rakes)\n",
    "    nodal_plane_dist = pmf.PMF([(prob, mech) \n",
    "                                for mech in mechanisms])\n",
    "\n",
    "    # derived parameters\n",
    "    if np.array(mags).size > 1:\n",
    "        delta_m = np.mean(np.diff(mags))\n",
    "    else:\n",
    "        delta_m = 1.\n",
    "    mag_freq_dist = mfd.TruncatedGRMFD(\n",
    "        min_mag=mags.min() - delta_m/2, \n",
    "        max_mag=mags.max() + delta_m/2, \n",
    "        bin_width=delta_m, \n",
    "        a_val=5.0, b_val=1.0),\n",
    "\n",
    "    hypocenter = geo.Point(hypo_lon, hypo_lat, hypo_depth)\n",
    "\n",
    "    source = src.PointSource(\n",
    "        source_id='1',\n",
    "        name='test',\n",
    "        tectonic_region_type=tectonic_region_type,\n",
    "        mfd=mag_freq_dist[0],\n",
    "        rupture_mesh_spacing=2.,\n",
    "        magnitude_scaling_relationship=msr.WC1994(),\n",
    "        rupture_aspect_ratio=1.,\n",
    "        temporal_occurrence_model=tom.PoissonTOM(50.),\n",
    "        upper_seismogenic_depth=0.2*hypo_depth,\n",
    "        lower_seismogenic_depth=2*hypo_depth,\n",
    "        location=hypocenter,\n",
    "        nodal_plane_distribution=nodal_plane_dist,\n",
    "        hypocenter_distribution=pmf.PMF([(1, hypo_depth)]))\n",
    "\n",
    "    # set up sites\n",
    "    lons, lats = geo.geodetic.point_at(hypo_lon, hypo_lat, \n",
    "                                       site_azimuth, distances)\n",
    "    site_locations = [geo.Point(lon, lat) for lon, lat in zip(lons, lats)]\n",
    "    site_list = [sit.Site(location=loc, vs30=vs30, \n",
    "                    vs30measured=True, z1pt0=40., z2pt5=1.0) \n",
    "                 for vs30 in vs30s \n",
    "                 for loc in site_locations]\n",
    "    site_collection = sit.SiteCollection(site_list)\n",
    "\n",
    "    # compute ground motion\n",
    "    context_maker = gsim.base.ContextMaker([gmpe])\n",
    "    empty = True\n",
    "    for rupture in source.iter_ruptures():\n",
    "\n",
    "        # tweak required because ``min_mag`` and ``max_mag`` are rounded by \n",
    "        # TruncatedGRMFD so that  both are divisible by ``bin_width``\n",
    "        rupture.mag = rupture.mag - delta_m/2.\n",
    "        sctx, rctx, dctx = context_maker.make_contexts(\n",
    "            site_collection, rupture)\n",
    "        for i, im_type in enumerate(im_types):\n",
    "            mean, [stddev] = gmpe.get_mean_and_stddevs(\n",
    "                sctx, rctx, dctx, im_type, uncertainty_types)\n",
    "            if i == 0:\n",
    "                df_mean = pd.DataFrame({\n",
    "                    'rup_mag': np.full_like(mean, rctx.mag),\n",
    "                    'rup_rake': np.full_like(mean, rctx.rake),\n",
    "                    'dist_rjb': dctx.rjb,\n",
    "                    'site_vs30': sctx.vs30,\n",
    "                    'damping': im_type.damping,\n",
    "                        'S': (gmpe.get_site_type_dummy_variables(sctx)).astype('float'),\n",
    "                        'H': np.full_like(mean, float(gmpe.get_fault_type_dummy_variables(rctx)))})\n",
    "                df_stddev = df_mean.copy()\n",
    "                df_mean['result_type'] = 'MEAN'\n",
    "                df_stddev['result_type'] = 'TOTAL_STDDEV'\n",
    "            df_mean[str(im_type.period)] = np.exp(mean)\n",
    "            df_stddev[str(im_type.period)] = np.exp(stddev)\n",
    "        if empty:\n",
    "            df_means = df_mean\n",
    "            df_stddevs = df_stddev\n",
    "            empty = False\n",
    "        else:\n",
    "            df_means = pd.concat((df_means, df_mean), ignore_index=True)\n",
    "            df_stddevs = pd.concat((df_stddevs, df_stddev), ignore_index=True)\n",
    "    \n",
    "    df_means.sort(['rup_rake','site_vs30','rup_mag','dist_rjb'], inplace=True)\n",
    "    df_stddevs.sort(['rup_rake','site_vs30','rup_mag','dist_rjb'], inplace=True)\n",
    "    df_means.index = range(len(df_means))\n",
    "    df_stddevs.index = range(len(df_stddevs))\n",
    "        \n",
    "    #df_means = df_means.set_index(['rup_rake','site_vs30','rup_mag','dist_rjb']).sort()\n",
    "    #df_stddevs = df_stddevs.set_index(['rup_rake','site_vs30','rup_mag','dist_rjb']).sort()\n",
    "\n",
    "    return (df_means, df_stddevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_gmpe(gmpe, mags, rakes, distances, vs30s, im_types):\n",
    "    \n",
    "    rctx = gsim.base.RuptureContext()\n",
    "    sctx = gsim.base.SitesContext()\n",
    "    dctx = gsim.base.DistancesContext()\n",
    "\n",
    "    empty = True\n",
    "    for mag in mags:\n",
    "        for rake in rakes:\n",
    "            \n",
    "            rctx.mag = mag\n",
    "            rctx.rake = rake\n",
    "            dctx.rjb = np.tile(distances, vs30s.size)\n",
    "            sctx.vs30 = np.repeat(vs30s, distances.size)\n",
    "            \n",
    "            for i, im_type in enumerate(im_types):\n",
    "\n",
    "                mean, [stddev] = gmpe.get_mean_and_stddevs(\n",
    "                    sctx, rctx, dctx, im_type, uncertainty_types)\n",
    "                                \n",
    "                if i == 0:\n",
    "                    df_mean = pd.DataFrame({\n",
    "                        'rup_mag': np.full_like(mean, rctx.mag),\n",
    "                        'rup_rake': np.full_like(mean, rctx.rake),\n",
    "                        'dist_rjb': dctx.rjb,\n",
    "                        'site_vs30': sctx.vs30,\n",
    "                        'damping': im_type.damping,\n",
    "                        'S': (gmpe.get_site_type_dummy_variables(sctx)).astype('float'),\n",
    "                        'H': np.full_like(mean, float(gmpe.get_fault_type_dummy_variables(rctx)))})\n",
    "                    df_stddev = df_mean.copy()\n",
    "                    df_mean['result_type'] = 'MEAN'\n",
    "                    df_stddev['result_type'] = 'TOTAL_STDDEV'\n",
    "                df_mean[str(im_type.period)] = np.exp(mean)\n",
    "                df_stddev[str(im_type.period)] = stddev\n",
    "                \n",
    "            if empty:\n",
    "                df_means = df_mean\n",
    "                df_stddevs = df_stddev\n",
    "                empty = False\n",
    "            else:\n",
    "                df_means = pd.concat((df_means, df_mean), ignore_index=True)\n",
    "                df_stddevs = pd.concat((df_stddevs, df_stddev), ignore_index=True)\n",
    "    \n",
    "    df_means.sort(['rup_rake','site_vs30','rup_mag','dist_rjb'], inplace=True)\n",
    "    df_stddevs.sort(['rup_rake','site_vs30','rup_mag','dist_rjb'], inplace=True)\n",
    "    df_means.index = range(len(df_means))\n",
    "    df_stddevs.index = range(len(df_stddevs))\n",
    "    \n",
    "    #df_means = df_means.set_index(['rup_rake','site_vs30','rup_mag','dist_rjb']).sort()\n",
    "    #df_stddevs = df_stddevs.set_index(['rup_rake','site_vs30','rup_mag','dist_rjb']).sort()\n",
    "\n",
    "    return (df_means, df_stddevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate data for Figure 6\n",
    "mags = np.array([5., 6., 7.])\n",
    "rakes = np.array([0., 90.]) # degrees\n",
    "#distances = tb.logspace(1, 200, 6) # km\n",
    "distances = np.array([1., 1.5, 2.2, 3.3, 4.7, 6.8, \n",
    "                      10., 15., 22., 33., 47., 68., \n",
    "                      100., 150.]) # km\n",
    "vs30s = np.array([500., 2000.]) # m/s\n",
    "im_types = [imt.SA(0.04, 5)]\n",
    "\n",
    "df_means, df_stddevs = compute_gmpe(gmpe, mags, rakes, distances, vs30s, im_types)\n",
    "\n",
    "pd.concat((df_means.head(), df_means.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate data for Figures 7-9\n",
    "mags = np.array([5., 6., 7.])\n",
    "rakes = np.array([0., 90.]) # degrees\n",
    "distances = np.array([10., 50., 100.]) # km\n",
    "vs30s = np.array([500., 2000.]) # m/s\n",
    "im_types = [imt.SA(T, 5) for T in df_coeffs['T']]\n",
    "\n",
    "df_means2, df_stddevs2 = compute_gmpe(gmpe, mags, rakes, distances, vs30s, im_types)\n",
    "pd.concat((df_means2.head(), df_means2.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat((df_stddevs2.head(), df_stddevs2.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that warning is raised for normal faulting\n",
    "rctx = gsim.base.RuptureContext()\n",
    "sctx = gsim.base.SitesContext()\n",
    "dctx = gsim.base.DistancesContext()\n",
    "\n",
    "rctx.mag = np.array([6.])\n",
    "rctx.rake = np.array([-90.])\n",
    "dctx.rjb = np.array([100.])\n",
    "sctx.vs30 = np.array([1000.])\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    # Cause all warnings to always be triggered.\n",
    "    warnings.simplefilter('always')\n",
    "    # Trigger a warning.\n",
    "    mean, [stddev] = gmpe.get_mean_and_stddevs(\n",
    "        sctx, rctx, dctx, im_types[0], uncertainty_types)\n",
    "    # Verify some things\n",
    "    assert len(w) == 1\n",
    "    assert issubclass(w[-1].category, UserWarning)\n",
    "    assert 'normal' in str(w[-1].message).lower()\n",
    "\n",
    "print mean, '+/-', stddev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# produce Figure 6\n",
    "digitized_template = 'digitized/M%d_S%d_H%d_%gs.csv'\n",
    "\n",
    "Ss = sorted(list(set(df_means['S'])))\n",
    "Hs = sorted(list(set(df_means['H'])))\n",
    "Rjbs = sorted(list(set(df_means['dist_rjb'])))\n",
    "fig, axes = plt.subplots(len(Ss), len(Hs), figsize=(8,6),\n",
    "                         sharex=True, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.075, hspace=0.1)\n",
    "for i, S in enumerate(Ss):\n",
    "    for j, H in enumerate(Hs):\n",
    "        fig.sca(axes[i,j])\n",
    "        df_axes = df_means[\n",
    "            (df_means['S'] == S) &\n",
    "            (df_means['H'] == H)]\n",
    "        axis_label = 'S=%g\\nH=%g' % (S, H)\n",
    "        fig.gca().add_artist(AnchoredText(axis_label, loc=1, frameon=False))\n",
    "\n",
    "        for mag in set(df_axes['rup_mag']):\n",
    "            df_trace = df_axes[df_axes['rup_mag'] == mag]\n",
    "                \n",
    "            trace_label = 'M=%g' % mag\n",
    "            h = plt.loglog(df_trace['dist_rjb'], df_trace[str(im_types[0].period)]*g, \n",
    "                       label=trace_label, alpha=0.5)\n",
    "            \n",
    "            digitized_file = digitized_template % (mag, S, H, im_types[0].period)\n",
    "            if os.path.exists(digitized_file):\n",
    "                data = np.genfromtxt(digitized_file, delimiter=',')\n",
    "                plt.plot(data[:,0], data[:,1], \n",
    "                         color=h[0].get_color(), marker='x', \n",
    "                         linestyle='none', alpha=0.5)\n",
    "            else:\n",
    "                print '%s not available' % digitized_file\n",
    "                \n",
    "for ax in axes:\n",
    "    ax[0].set_xlim((min(Rjbs), max(Rjbs)))\n",
    "    ax[0].set_ylim((0.1, 5))\n",
    "for ax in axes[1,:]:\n",
    "    ax.set_xlabel('Joyner-Boore Distance [km]')\n",
    "for ax in axes[:,0]:\n",
    "    ax.set_ylabel('SA(T=%g s, $\\\\xi$=%g%%) [m/s$^2$]' \n",
    "          % (im_types[0].period, im_types[0].damping))\n",
    "axes[1,0].legend(loc='lower left', labelspacing=0, fontsize=10, frameon=False)\n",
    "plt.savefig('Figure_6_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produce Figures 7-9\n",
    "digitized_template = 'digitized/M%d_S%d_H%d_%gkm.csv'\n",
    "\n",
    "Ss = sorted(list(set(df_means2['S'])))\n",
    "Hs = sorted(list(set(df_means2['H'])))\n",
    "Rjbs = sorted(list(set(df_means2['dist_rjb'])))\n",
    "fig, axes = plt.subplots(len(Rjbs), 1, figsize=(6,10), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "for i, dist in enumerate(Rjbs):\n",
    "    \n",
    "    fig.sca(axes[i])\n",
    "    df_axes = df_means2[df_means2['dist_rjb'] == dist]\n",
    "    axis_label = '%g km' % dist\n",
    "    fig.gca().add_artist(AnchoredText(axis_label, loc=2, frameon=False))\n",
    "    \n",
    "    S = 0\n",
    "    for H in Hs:\n",
    "        for mag in set(df_axes['rup_mag']):\n",
    "            df_trace = df_axes[\n",
    "                (df_axes['rup_mag'] == mag) &\n",
    "                (df_axes['S'] == S) & \n",
    "                (df_axes['H'] == H)]\n",
    "                \n",
    "            trace_label = 'M=%g, S=%d, H=%d' % (mag, S, H)\n",
    "            if df_trace.size == 0:\n",
    "                print 'No data found for', trace_label\n",
    "            \n",
    "            data_trace = df_trace.loc[:,np.array(map(isnumeric, df_trace.keys()))].T\n",
    "            T = [float(item) for item in data_trace.index]\n",
    "            SA = data_trace.values*g\n",
    "            h = plt.plot(T, SA, label=trace_label, alpha=0.5)\n",
    "            \n",
    "            digitized_file = digitized_template % (mag, S, H, dist)\n",
    "            if os.path.exists(digitized_file):\n",
    "                data = np.genfromtxt(digitized_file, delimiter=',')\n",
    "                plt.plot(data[:,0], data[:,1], \n",
    "                         color=h[0].get_color(), marker='x', \n",
    "                         linestyle='none', alpha=0.5)\n",
    "\n",
    "            else:\n",
    "                print '%s not available' % digitized_file\n",
    "                \n",
    "for ax in axes:\n",
    "    ax.set_xlim((0, max(T)))\n",
    "    ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "axes[-1].set_xlabel('Period [s]')\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('SA($\\\\xi$=%g%%) [m/s$^2$]' % (im_types[0].damping))\n",
    "axes[0].legend(loc='upper right', labelspacing=0, fontsize=10, frameon=False)\n",
    "plt.savefig('Figures_7-9_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# produce plot of estimated residuals\n",
    "Ss = sorted(list(set(df_stddevs2['S'])))\n",
    "Hs = sorted(list(set(df_stddevs2['H'])))\n",
    "Rjbs = sorted(list(set(df_stddevs2['dist_rjb'])))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "dist = Rjbs[0]   \n",
    "df_axes = df_stddevs2[df_stddevs2['dist_rjb'] == dist]\n",
    "\n",
    "S = Ss[0]\n",
    "H = Hs[0]\n",
    "mag = sorted(list(set(df_axes['rup_mag'])))[0]\n",
    "df_trace = df_axes[\n",
    "    (df_axes['rup_mag'] == mag) &\n",
    "    (df_axes['S'] == S) & \n",
    "    (df_axes['H'] == H)]\n",
    "\n",
    "trace_label = 'M=%g, S=%d, H=%d' % (mag, S, H)\n",
    "if df_trace.size == 0:\n",
    "    print 'No data found for', trace_label\n",
    "\n",
    "data_trace = df_trace.loc[:,np.array(map(isnumeric, df_trace.keys()))].T\n",
    "T = [float(item) for item in data_trace.index]\n",
    "sigma = data_trace.values\n",
    "plt.plot(T, sigma, label=trace_label, alpha=0.5)\n",
    "                            \n",
    "ax.set_xlim((0, max(T)))\n",
    "ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "ax.set_xlabel('Period [s]')\n",
    "ax.set_ylabel('Total standard deviation $\\sigma$')\n",
    "plt.savefig('Sigma_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produce result file for unittest\n",
    "test_path = '/home/nick/src/python/GEM/oq-hazardlib/openquake/hazardlib/tests/gsim/data/SDBK09/'\n",
    "means_file = os.path.join(test_path, 'SDBK09_MEAN.csv')\n",
    "stddev_file = os.path.join(test_path, 'SDBK09_STD_TOTAL.csv')\n",
    "#df_means2.drop(['H','S'], axis=1).to_csv(means_file, index=False)\n",
    "df_stddevs2.drop(['H','S'], axis=1).to_csv(stddev_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load dataset provided by authors\n",
    "ref_file = os.path.join(test_path, 'SDBK09_MEAN.csv')\n",
    "df_ref = pd.read_csv(ref_file, na_values='nan')\n",
    "\n",
    "df_ref.sort(['rup_rake','site_vs30','rup_mag','dist_rjb'], inplace=True)\n",
    "df_ref.index = range(len(df_ref))\n",
    "\n",
    "mags = np.sort(np.array(list(set(df_ref['rup_mag']))))\n",
    "rakes = np.sort(np.array(list(set(df_ref['rup_rake']))))\n",
    "#rakes = rakes[rakes >= 0]\n",
    "Rjbs = np.sort(np.array(list(set(df_ref['dist_rjb']))))\n",
    "vs30s = np.sort(np.array(list(set(df_ref['site_vs30']))))\n",
    "Ts = np.sort(np.array([float(item) for item in \n",
    "     df_ref.loc[:,np.array(map(isnumeric, df_ref.keys()))]]))\n",
    "im_types = [imt.SA(T) for T in Ts]\n",
    "\n",
    "print mags, rakes, Rjbs, vs30s\n",
    "print Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new, _ = compute_gmpe(gmpe, mags, rakes, Rjbs, vs30s, im_types)\n",
    "df_new = df_new.drop(['H','S'], axis=1)\n",
    "df_ref = df_ref[df_new.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_traces = len(rakes)*len(vs30s)*len(mags)\n",
    "color_cycle = plt.cm.jet(np.linspace(0, 1, n_traces))\n",
    "\n",
    "fig, axes = plt.subplots(len(Rjbs), 1, figsize=(6,15), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "for i, dist in enumerate(Rjbs):\n",
    "    \n",
    "    fig.sca(axes[i])\n",
    "    axis_label = 'rjb=%g' % dist\n",
    "    fig.gca().add_artist(AnchoredText(axis_label, loc=1, frameon=False))\n",
    "    fig.gca().set_color_cycle(color_cycle)\n",
    "   \n",
    "    for rake in rakes:\n",
    "        for vs30 in vs30s:\n",
    "            for mag in mags:\n",
    "                trace_label = 'mag=%g, rake=%g, vs30=%g' % (mag, rake, vs30)\n",
    "                \n",
    "                df_trace = df_ref[\n",
    "                    (df_ref['dist_rjb'] == dist) &\n",
    "                    (df_ref['rup_mag'] == mag) &\n",
    "                    (df_ref['rup_rake'] == rake) & \n",
    "                    (df_ref['site_vs30'] == vs30)]\n",
    "\n",
    "                if df_trace.size == 0:\n",
    "                    print 'No reference found for', trace_label\n",
    "\n",
    "                data_trace = df_trace.loc[:,np.array(map(isnumeric, df_trace.keys()))].T\n",
    "                SA = np.reshape(data_trace.values.T, (-1,))*g\n",
    "                h = plt.plot(Ts, SA, label=trace_label, alpha=0.5)\n",
    "                \n",
    "                df_trace2 = df_new[\n",
    "                    (df_new['dist_rjb'] == dist) &\n",
    "                    (df_new['rup_mag'] == mag) &\n",
    "                    (df_new['rup_rake'] == rake) & \n",
    "                    (df_new['site_vs30'] == vs30)]\n",
    "                \n",
    "                if df_trace2.size == 0:\n",
    "                    print 'No new value found for', trace_label\n",
    "\n",
    "                data_trace2 = df_trace2.loc[:,np.array(map(isnumeric, df_trace2.keys()))].T\n",
    "                SA2 = np.reshape(data_trace2.values.T, (-1,))*g\n",
    "                plt.plot(Ts, SA2, linestyle='none', marker='x', \n",
    "                         color=h[0].get_color(), alpha=0.5)\n",
    "                \n",
    "for ax in axes:\n",
    "    ax.set_xlim((0, max(Ts)))\n",
    "    ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "axes[-1].set_xlabel('Period [s]')\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('SA($\\\\xi$=%g%%) [m/s$^2$]' % (im_types[0].damping))\n",
    "axes[0].legend(loc='upper left', labelspacing=0, fontsize=10, bbox_to_anchor=(1, 1))\n",
    "plt.savefig('Reference_result.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compare(df_new, df_ref):\n",
    "    numeric = np.array([[isnumeric(item) for item in row[1]] for row in df_ref.iterrows()])\n",
    "    non_zero = (df_ref != 0) & numeric\n",
    "    df_dif = df_ref.copy()\n",
    "    df_dif = df_dif.where(~numeric, df_new.where(numeric) - df_ref.where(numeric))\n",
    "    df_dif = df_dif.where(~non_zero, df_dif.where(non_zero)/df_ref.where(non_zero))\n",
    "    df_dif = df_dif.where(numeric, df_new.where(~numeric) != df_ref.where(~numeric))\n",
    "    \n",
    "    return df_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize the largest discrepancies\n",
    "threshhold = 1e-8\n",
    "\n",
    "ne_stacked = (compare(df_new, df_ref) > threshhold).stack()\n",
    "changed = ne_stacked[ne_stacked]\n",
    "changed.index.names = ['index', 'column']\n",
    "\n",
    "difference_locations = np.where(compare(df_new, df_ref) > threshhold)\n",
    "changed_from = df_new.values[difference_locations]\n",
    "changed_to = df_ref.values[difference_locations]\n",
    "pd.DataFrame({'from': changed_from, 'factor': changed_from/changed_to}, index=changed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
