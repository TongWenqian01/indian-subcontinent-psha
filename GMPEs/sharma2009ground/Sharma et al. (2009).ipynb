{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharma et al. (2009)\n",
    "\n",
    "In which the GMPE of Sharma et al. (2009) is implemented. First coefficient tables are reprocessed for cut & paste in to the .py source code. Then, key figures in the original paper are reproduced for validation. Finally, test vectors are produced for automatic code verification using unittest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from scipy.constants import g\n",
    "\n",
    "import toolbox as tb\n",
    "%autoreload 2\n",
    "import gmpe_tools as gt\n",
    "\n",
    "from openquake.hazardlib import gsim, imt, const\n",
    "\n",
    "from openquake.hazardlib.gsim.sharma_2009 import SharmaEtAl2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_coeffs = pd.DataFrame.from_csv('Tables/Table2.csv', index_col=None)\n",
    "df_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sharma_file = 'correspondence/sharma coefficients.csv'\n",
    "df_coeffs2 = pd.DataFrame.from_csv(sharma_file, index_col=None)\n",
    "df_coeffs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how peculiar that there is just one repeated row (except for sigma) ...\n",
    "# no mention of coefficients being reused for 0.1 and 0.2 s in the paper ...\n",
    "df_coeffs2.diff() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients = ['b%d' for i in range(1,7)]\n",
    "df_coeffs.plot(x='T', y=['b1', 'b2', 'b3', 'b5', 'b6'], figsize=(6, 8), grid=True)\n",
    "plt.axhspan(-0.1, 0.1, color='0.5', alpha=0.5)\n",
    "plt.savefig('Sharma_coefficients.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Table2.txt','w') as f:\n",
    "    f.write(df_coeffs[['T', 'b1', 'b2', 'b3', 'b5', 'b6', 'sigma']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "gmpe = SharmaEtAl2009()\n",
    "print(type(gmpe).__name__)\n",
    "print('Supported tectonic region: %s' \n",
    "      % gmpe.DEFINED_FOR_TECTONIC_REGION_TYPE)\n",
    "print('Supported intensity measure types: %s' \n",
    "      % ', '.join([item.__name__ for item \n",
    "                   in gmpe.DEFINED_FOR_INTENSITY_MEASURE_TYPES]))\n",
    "print('Supported component: %s' \n",
    "      % gmpe.DEFINED_FOR_INTENSITY_MEASURE_COMPONENT)\n",
    "print('Supported standard deviations: %s' \n",
    "      % ', '.join([item for item              \n",
    "                   in gmpe.DEFINED_FOR_STANDARD_DEVIATION_TYPES]))\n",
    "print('Required site parameters: %s' \n",
    "      % ', '.join([item for item in gmpe.REQUIRES_SITES_PARAMETERS]))\n",
    "print('Required rupture parameters: %s' \n",
    "      % ', '.join([item for item in gmpe.REQUIRES_RUPTURE_PARAMETERS]))\n",
    "print('Required distance parameters: %s' \n",
    "      % ', '.join([item for item in gmpe.REQUIRES_DISTANCES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_dummy_variables(gmpe, df_means):\n",
    "    sctx = gsim.base.SitesContext()\n",
    "    sctx.vs30 = df_means['site_vs30'].values\n",
    "    S = gmpe.get_site_type_dummy_variables(sctx)\n",
    "    df_means['S'] = S.astype('float')\n",
    "\n",
    "    H = [gmpe.get_fault_type_dummy_variables(tb.Structure(rake=rake)) \n",
    "         for rake in df_means['rup_rake'].astype('float')]\n",
    "    df_means['H'] = np.array(H).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate data for Figure 6\n",
    "mags = np.array([5., 6., 7.])\n",
    "rakes = np.array([0., 90.]) # degrees\n",
    "distances = tb.logspace(1, 200, 6) # km\n",
    "vs30s = np.array([500., 2000.]) # m/s\n",
    "im_types = [imt.SA(0.04, 5)]\n",
    "\n",
    "df_means, df_stddevs = gt.compute_gmpe(gmpe, mags, rakes, distances, \n",
    "                                       vs30s, im_types)\n",
    "add_dummy_variables(gmpe, df_means)\n",
    "\n",
    "pd.concat((df_means.head(), df_means.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate data for Figures 7-9\n",
    "mags = np.array([5., 6., 7.])\n",
    "rakes = np.array([0., 90.]) # degrees\n",
    "distances = np.array([10., 50., 100.]) # km\n",
    "vs30s = np.array([500., 2000.]) # m/s\n",
    "im_types = [imt.SA(T, 5) for T in df_coeffs['T']]\n",
    "\n",
    "df_means2, df_stddevs2 = gt.compute_gmpe(gmpe, mags, rakes, distances, vs30s, im_types)\n",
    "add_dummy_variables(gmpe, df_means2)\n",
    "\n",
    "pd.concat((df_means2.head(), df_means2.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_normal = np.array([False])\n",
    "is_reverse = np.array([False])\n",
    "is_strike_slip = (~is_reverse).astype(float)\n",
    "is_strike_slip[is_normal] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(is_strike_slip, type(is_strike_slip), is_strike_slip.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat((df_stddevs2.head(), df_stddevs2.tail()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that warning is raised for normal faulting\n",
    "rctx = gsim.base.RuptureContext()\n",
    "sctx = gsim.base.SitesContext()\n",
    "dctx = gsim.base.DistancesContext()\n",
    "\n",
    "rctx.mag = np.array([6.])\n",
    "rctx.rake = np.array([-90.])\n",
    "dctx.rjb = np.array([100.])\n",
    "sctx.vs30 = np.array([1000.])\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    # Cause all warnings to always be triggered.\n",
    "    warnings.simplefilter('always')\n",
    "    # Trigger a warning.\n",
    "    mean, [stddev] = gmpe.get_mean_and_stddevs(\n",
    "        sctx, rctx, dctx, im_types[0], [const.StdDev.TOTAL])\n",
    "    # Verify some things\n",
    "    assert len(w) == 1\n",
    "    assert issubclass(w[-1].category, UserWarning)\n",
    "    assert 'not supported' in str(w[-1].message).lower()\n",
    "    assert np.all(np.isnan(mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# produce Figure 6\n",
    "digitized_template = 'digitized/M%d_S%d_H%d_%gs.csv'\n",
    "\n",
    "Ss = sorted(list(set(df_means['S'])))\n",
    "Hs = sorted(list(set(df_means['H'])))\n",
    "Rjbs = sorted(list(set(df_means['dist_rjb'])))\n",
    "fig, axes = plt.subplots(len(Ss), len(Hs), figsize=(8,6),\n",
    "                         sharex=True, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.075, hspace=0.1)\n",
    "for i, S in enumerate(Ss):\n",
    "    for j, H in enumerate(Hs):\n",
    "        ax = axes[i,j]\n",
    "        df_axes = df_means[\n",
    "            (df_means['S'] == S) &\n",
    "            (df_means['H'] == H)]\n",
    "        axis_label = 'S=%g\\nH=%g' % (S, H)\n",
    "        ax.add_artist(AnchoredText(axis_label, loc=1, \n",
    "                                          frameon=False))\n",
    "\n",
    "        for mag in set(df_axes['rup_mag']):\n",
    "            df_trace = df_axes[df_axes['rup_mag'] == mag]\n",
    "                \n",
    "            trace_label = 'M=%g' % mag\n",
    "            h = ax.loglog(df_trace['dist_rjb'], \n",
    "                           df_trace[im_types[0].period]*g, \n",
    "                       label=trace_label, alpha=0.5)\n",
    "            \n",
    "            digitized_file = digitized_template % (\n",
    "                mag, S, H, im_types[0].period)\n",
    "            if os.path.exists(digitized_file):\n",
    "                data = np.genfromtxt(digitized_file, delimiter=',')\n",
    "                ax.plot(data[:,0], data[:,1], \n",
    "                         color=h[0].get_color(), marker='x', \n",
    "                         linestyle='none', alpha=0.5)\n",
    "            else:\n",
    "                print '%s not available' % digitized_file\n",
    "                \n",
    "for ax in axes:\n",
    "    ax[0].set_xlim((min(Rjbs), max(Rjbs)))\n",
    "    ax[0].set_ylim((0.1, 5))\n",
    "for ax in axes[1,:]:\n",
    "    ax.set_xlabel('Joyner-Boore Distance [km]')\n",
    "for ax in axes[:,0]:\n",
    "    ax.set_ylabel('SA(T=%g s, $\\\\xi$=%g%%) [m/s$^2$]' \n",
    "          % (im_types[0].period, im_types[0].damping))\n",
    "axes[1,0].legend(loc='lower left', labelspacing=0, fontsize=10, \n",
    "                 frameon=False)\n",
    "plt.savefig('Figure_6_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produce Figures 7-9\n",
    "digitized_template = 'digitized/M%d_S%d_H%d_%gkm.csv'\n",
    "\n",
    "Ss = sorted(list(set(df_means2['S'])))\n",
    "Hs = sorted(list(set(df_means2['H'])))\n",
    "Rjbs = sorted(list(set(df_means2['dist_rjb'])))\n",
    "fig, axes = plt.subplots(len(Rjbs), 1, figsize=(6,10), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "for ax, dist in zip(axes, Rjbs):\n",
    "    \n",
    "    df_axes = df_means2[df_means2['dist_rjb'] == dist]\n",
    "    axis_label = '%g km' % dist\n",
    "    ax.add_artist(AnchoredText(axis_label, loc=2, frameon=False))\n",
    "    \n",
    "    S = 0\n",
    "    for H in Hs:\n",
    "        for mag in set(df_axes['rup_mag']):\n",
    "            df_trace = df_axes[\n",
    "                (df_axes['rup_mag'] == mag) &\n",
    "                (df_axes['S'] == S) & \n",
    "                (df_axes['H'] == H)]\n",
    "                \n",
    "            trace_label = 'M=%g, S=%d, H=%d' % (mag, S, H)\n",
    "            if df_trace.size == 0:\n",
    "                print 'No data found for', trace_label\n",
    "            \n",
    "            data_trace = df_trace.loc[:,np.array(map(tb.is_numeric, df_trace.keys()))].T\n",
    "            T = [float(item) for item in data_trace.index]\n",
    "            SA = data_trace.values*g\n",
    "            h = ax.plot(T, SA, label=trace_label, alpha=0.5)\n",
    "            \n",
    "            digitized_file = digitized_template % (mag, S, H, dist)\n",
    "            if os.path.exists(digitized_file):\n",
    "                data = np.genfromtxt(digitized_file, delimiter=',')\n",
    "                ax.plot(data[:,0], data[:,1],\n",
    "                        color=h[0].get_color(), marker='x', \n",
    "                        linestyle='none', alpha=0.5)\n",
    "\n",
    "            else:\n",
    "                print '%s not available' % digitized_file\n",
    "                \n",
    "for ax in axes:\n",
    "    ax.set_xlim((0, max(T)))\n",
    "    ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "axes[-1].set_xlabel('Period [s]')\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('SA($\\\\xi$=%g%%) [m/s$^2$]' % (im_types[0].damping))\n",
    "axes[0].legend(loc='upper right', labelspacing=0, fontsize=10, frameon=False)\n",
    "plt.savefig('Figures_7-9_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# produce plot of estimated residuals\n",
    "vs30s = sorted(list(set(df_stddevs2['site_vs30'])))\n",
    "rakes = sorted(list(set(df_stddevs2['rup_rake'])))\n",
    "Rjbs = sorted(list(set(df_stddevs2['dist_rjb'])))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "dist = Rjbs[0]   \n",
    "df_axes = df_stddevs2[df_stddevs2['dist_rjb'] == dist]\n",
    "\n",
    "vs30 = vs30s[0]\n",
    "rake = rakes[0]\n",
    "mag = sorted(list(set(df_axes['rup_mag'])))[0]\n",
    "df_trace = df_axes[\n",
    "    (df_axes['rup_mag'] == mag) &\n",
    "    (df_axes['site_vs30'] == vs30) & \n",
    "    (df_axes['rup_rake'] == rake)]\n",
    "\n",
    "trace_label = 'M=%g, vs30=%d, rake=%d' % (mag, vs30, rake)\n",
    "if df_trace.size == 0:\n",
    "    print 'No data found for', trace_label\n",
    "\n",
    "data_trace = df_trace.loc[:,np.array(map(tb.is_numeric, df_trace.keys()))].T\n",
    "T = [float(item) for item in data_trace.index]\n",
    "sigma = data_trace.values\n",
    "plt.plot(T, sigma, label=trace_label, alpha=0.5)\n",
    "                            \n",
    "ax.set_xlim((0, max(T)))\n",
    "ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "ax.set_xlabel('Period [s]')\n",
    "ax.set_ylabel('Total standard deviation $\\sigma$')\n",
    "plt.savefig('Sigma_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produce result file for unittest\n",
    "test_path = '/home/nick/src/python/GEM/oq-hazardlib/openquake/hazardlib/tests/gsim/data/SDBK09/'\n",
    "means_file = os.path.join(test_path, 'SDBK09_MEAN.csv')\n",
    "stddev_file = os.path.join(test_path, 'SDBK09_STD_TOTAL.csv')\n",
    "\n",
    "# for the standard deviations we must generate the test result file ourselves\n",
    "df_stddevs2.columns = [str(item) for item in df_stddevs2.columns]\n",
    "df_stddevs2.to_csv(stddev_file, index=False, float_format='%.7g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load dataset provided by authors\n",
    "means_file = os.path.join(test_path, 'SDBK09_MEAN.csv')\n",
    "df_ref = pd.read_csv(means_file)\n",
    "df_ref = gt.df_massage(df_ref)\n",
    "\n",
    "mags = np.sort(np.array(list(set(df_ref['rup_mag']))))\n",
    "rakes = np.sort(np.array(list(set(df_ref['rup_rake']))))\n",
    "#rakes = rakes[rakes >= 0]\n",
    "Rjbs = np.sort(np.array(list(set(df_ref['dist_rjb']))))\n",
    "vs30s = np.sort(np.array(list(set(df_ref['site_vs30']))))\n",
    "Ts = np.sort(np.array([float(item) for item in \n",
    "     df_ref.loc[:,np.array(map(tb.is_numeric, df_ref.keys()))]]))\n",
    "im_types = [imt.SA(T) for T in Ts]\n",
    "\n",
    "print mags, rakes, Rjbs, vs30s\n",
    "print Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new, _ = gt.compute_gmpe(gmpe, mags, rakes, Rjbs, vs30s, im_types)\n",
    "df_new = gt.df_massage(df_new)\n",
    "df_new = df_new[df_ref.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_traces = len(rakes)*len(vs30s)*len(mags)\n",
    "color_cycle = plt.cm.jet(np.linspace(0, 1, n_traces))\n",
    "\n",
    "fig, axes = plt.subplots(len(Rjbs), 1, figsize=(6,15), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "for i, dist in enumerate(Rjbs):\n",
    "    \n",
    "    fig.sca(axes[i])\n",
    "    axis_label = 'rjb=%g' % dist\n",
    "    fig.gca().add_artist(AnchoredText(axis_label, loc=1, frameon=False))\n",
    "    fig.gca().set_color_cycle(color_cycle)\n",
    "   \n",
    "    for rake in rakes:\n",
    "        for vs30 in vs30s:\n",
    "            for mag in mags:\n",
    "                trace_label = 'mag=%g, rake=%g, vs30=%g' % (mag, rake, vs30)\n",
    "                \n",
    "                df_trace = df_ref[\n",
    "                    (df_ref['dist_rjb'] == dist) &\n",
    "                    (df_ref['rup_mag'] == mag) &\n",
    "                    (df_ref['rup_rake'] == rake) & \n",
    "                    (df_ref['site_vs30'] == vs30)]\n",
    "\n",
    "                if df_trace.size == 0:\n",
    "                    print 'No reference found for', trace_label\n",
    "\n",
    "                data_trace = df_trace.loc[:,np.array(map(tb.is_numeric, df_trace.keys()))].T\n",
    "                SA = np.reshape(data_trace.values.T, (-1,))*g\n",
    "                h = plt.plot(Ts, SA, label=trace_label, alpha=0.5)\n",
    "                \n",
    "                df_trace2 = df_new[\n",
    "                    (df_new['dist_rjb'] == dist) &\n",
    "                    (df_new['rup_mag'] == mag) &\n",
    "                    (df_new['rup_rake'] == rake) & \n",
    "                    (df_new['site_vs30'] == vs30)]\n",
    "                \n",
    "                if df_trace2.size == 0:\n",
    "                    print 'No new value found for', trace_label\n",
    "\n",
    "                data_trace2 = df_trace2.loc[:,np.array(map(tb.is_numeric, df_trace2.keys()))].T\n",
    "                SA2 = np.reshape(data_trace2.values.T, (-1,))*g\n",
    "                plt.plot(Ts, SA2, linestyle='none', marker='x', \n",
    "                         color=h[0].get_color(), alpha=0.5)\n",
    "                \n",
    "for ax in axes:\n",
    "    ax.set_xlim((0, max(Ts)))\n",
    "    ax.set_ylim((0, ax.get_ylim()[1]))\n",
    "axes[-1].set_xlabel('Period [s]')\n",
    "for ax in axes:\n",
    "    ax.set_ylabel('SA($\\\\xi$=%g%%) [m/s$^2$]' % (im_types[0].damping))\n",
    "axes[0].legend(loc='upper left', labelspacing=0, fontsize=10, bbox_to_anchor=(1, 1))\n",
    "plt.savefig('Reference_result.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize the largest discrepancies\n",
    "threshhold = 1e-8\n",
    "\n",
    "ne_stacked = (tb.df_compare(df_new, df_ref) > threshhold).stack()\n",
    "changed = ne_stacked[ne_stacked]\n",
    "changed.index.names = ['index', 'column']\n",
    "\n",
    "difference_locations = np.where(tb.df_compare(df_new, df_ref) > threshhold)\n",
    "changed_from = df_new.values[difference_locations]\n",
    "changed_to = df_ref.values[difference_locations]\n",
    "pd.DataFrame({'from': changed_from, 'percent': 100*(changed_to/changed_from - 1)}, index=changed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
