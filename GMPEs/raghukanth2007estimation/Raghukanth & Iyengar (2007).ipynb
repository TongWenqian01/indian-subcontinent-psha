{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raghukanth & Iyengar (2007)\n",
    "\n",
    "In which the GMPE of Raghukanth & Iyengar (2007) is implemented. First coefficient tables are reprocessed for cut & paste in to the .py source code. Then, key figures in the original paper are reproduced for validation. Finally, test vectors are produced for automatic code verification using unittest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import toolbox as tb\n",
    "%autoreload 2\n",
    "import gmpe_tools as gt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "from IPython.display import display\n",
    "\n",
    "from openquake.hazardlib import gsim\n",
    "\n",
    "from openquake.hazardlib.gsim.raghukanth_iyengar_2007 \\\n",
    "    import (RaghukanthIyengar2007, \n",
    "            RaghukanthIyengar2007KoynaWarna, \n",
    "            RaghukanthIyengar2007Southern, \n",
    "            RaghukanthIyengar2007WesternCentral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmpe_short = 'RAIY07'\n",
    "gmpes = [\n",
    "    RaghukanthIyengar2007(),\n",
    "    RaghukanthIyengar2007KoynaWarna(), \n",
    "    RaghukanthIyengar2007Southern(),\n",
    "    RaghukanthIyengar2007WesternCentral(),\n",
    "]\n",
    "regions_short = [\n",
    "    'PI',\n",
    "    'KW',\n",
    "    'SI',\n",
    "    'WC',\n",
    "]\n",
    "regions_long = [\n",
    "    'Peninsular India',\n",
    "    'Koyna-Warna',\n",
    "    'Southern',\n",
    "    'Western-Central',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bedrocks_csv = [\n",
    "    'Table 3.csv',\n",
    "    'Table 2a.csv', \n",
    "    'Table 2b.csv', \n",
    "    'Table 2c.csv', \n",
    "]\n",
    "dfs_bedrock = [pd.DataFrame.from_csv('Tables/%s' % name) \n",
    "               for name in bedrocks_csv]\n",
    "bedrocks_txt = [name.replace('.csv','.txt') for name in bedrocks_csv]\n",
    "for df_bedrock, bedrock_txt in zip(dfs_bedrock, bedrocks_txt):\n",
    "    with open('Tables/%s' % bedrock_txt,'w') as f:\n",
    "        f.write(df_bedrock.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sites_csv = 'Tables/Table 5.csv'\n",
    "sites_txt = sites_csv.replace('.csv','.txt')\n",
    "df_sites = pd.DataFrame.from_csv(sites_csv, header=[0,1])\n",
    "for site_class in df_sites.columns.levels[0]:\n",
    "    site_txt = sites_csv.replace('.csv','%s.txt' % site_class.lower())\n",
    "    with open(site_txt,'w') as f:\n",
    "        f.write(df_sites[site_class].to_string(sparsify=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coefficients = ['c%d' % i for i in range(1,5)]\n",
    "multipliers = [1., 1., 10., 300.]\n",
    "fig, axes = plt.subplots(len(dfs_bedrock), 1, figsize=(6,10), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "\n",
    "for ax, df_bedrock, bedrock_csv, region_long \\\n",
    "        in zip(axes, dfs_bedrock, bedrocks_csv, regions_long):\n",
    "    row_label = '%s: %s' % (bedrock_csv.replace('.csv',''), region_long)\n",
    "    ax.set_ylabel(row_label)\n",
    "    for coeff, multiplier in zip(coefficients, multipliers):\n",
    "        label = coeff\n",
    "        if multiplier != 1:\n",
    "            label = '%gx %s' % (multiplier, label)\n",
    "        ax.semilogx(df_bedrock.index, multiplier*df_bedrock[coeff], \n",
    "                    marker='x', label=label)\n",
    "    ax.grid(which='both')\n",
    "    ax.set_ylim((-4, 4))\n",
    "    ax.set_xlim((0.01, 4))\n",
    "    \n",
    "ax.set_xlabel('Period $T$ [s]')\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.savefig('Bedrock_coefficients.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('Bedrock_coefficients.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_site_coeffs = df_sites.loc[:,(slice(None), slice('a1','a2'))]\n",
    "df_site_coeffs.plot(marker='x', logx=True)\n",
    "\n",
    "plt.ylabel('Table 5: Site Class Coefficients')\n",
    "plt.xlabel('Period $T$ [s]')\n",
    "plt.grid(which='both')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.savefig('Site_coefficients.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('Site_coefficients.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sigmas = df_sites.loc[:,(slice(None), slice('sigma','sigma'))]\n",
    "df_sigmas.columns = df_sigmas.columns.droplevel(1)\n",
    "df_sigmas.is_copy = False\n",
    "df_sigmas.loc[:,'bedrock'] = df_bedrock.loc[:,'sigma']\n",
    "df_sigmas.plot(marker='x', logx=True)\n",
    "\n",
    "plt.ylabel('Standard error $\\\\sigma(\\\\ln \\\\epsilon)$')\n",
    "plt.xlabel('Period $T$ [s]')\n",
    "plt.grid(which='both')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.savefig('Sigmas.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "for gmpe in gmpes[0:1]:\n",
    "    print(type(gmpe).__name__)\n",
    "    print('Supported tectonic region: %s' \n",
    "          % gmpe.DEFINED_FOR_TECTONIC_REGION_TYPE)\n",
    "    print('Supported intensity measure types: %s' \n",
    "          % ', '.join([item.__name__ for item \n",
    "                       in gmpe.DEFINED_FOR_INTENSITY_MEASURE_TYPES]))\n",
    "    print('Supported component: %s' \n",
    "          % gmpe.DEFINED_FOR_INTENSITY_MEASURE_COMPONENT)\n",
    "    print('Supported standard deviations: %s' \n",
    "          % ', '.join([item for item              \n",
    "                       in gmpe.DEFINED_FOR_STANDARD_DEVIATION_TYPES]))\n",
    "    print('Required site parameters: %s' \n",
    "          % ', '.join([item for item in gmpe.REQUIRES_SITES_PARAMETERS]))\n",
    "    print('Required rupture parameters: %s' \n",
    "          % ', '.join([item for item in gmpe.REQUIRES_RUPTURE_PARAMETERS]))\n",
    "    print('Required distance parameters: %s' \n",
    "          % ', '.join([item for item in gmpe.REQUIRES_DISTANCES]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate data for bedrock motion Figure 3\n",
    "mags = [6.5]\n",
    "rakes = [0] # degrees\n",
    "distances = [35., 100.] # km\n",
    "vs30s = 4000. # m/s\n",
    "im_types = sorted(gmpes[0].COEFFS_BEDROCK.sa_coeffs.keys())\n",
    "\n",
    "df_means = [gt.compute_gmpe(gmpe, mags, rakes, distances, vs30s, im_types)[0]\n",
    "            for gmpe in gmpes[1:]]\n",
    "\n",
    "df_stddevs = [gt.compute_gmpe(gmpe, mags, rakes, distances, vs30s, im_types)[1]\n",
    "            for gmpe in gmpes[1:]]\n",
    "\n",
    "df_means = pd.concat(df_means, keys=regions_short[1:], \n",
    "                     names=['gmpe','test'])\n",
    "df_means.reset_index(inplace=True)\n",
    "df_means.drop(['test'], axis=1, inplace=True)\n",
    "\n",
    "df_stddevs = pd.concat(df_stddevs, keys=regions_short[1:], \n",
    "                     names=['gmpe','test'])\n",
    "df_stddevs.reset_index(inplace=True)\n",
    "df_stddevs.drop(['test'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# produce Figure 3\n",
    "digitized_template = 'Digitized/M%g_R%gkm_%s.csv'\n",
    "empty = True\n",
    "\n",
    "numeric_cols = np.array([tb.is_numeric(item) for item in df_means.columns])\n",
    "extra_cols = df_means.columns[~numeric_cols]\n",
    "T = [float(item) for item in df_means.columns[numeric_cols]]\n",
    "\n",
    "gmpe_keys = sorted(list(set(df_means['gmpe'])))\n",
    "rhypos = sorted(list(set(df_means['dist_rhypo'])))\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for gmpe_key in gmpe_keys:\n",
    "    for rhypo in rhypos:\n",
    "                \n",
    "        df_trace = df_means[\n",
    "            (df_means['gmpe'] == gmpe_key) &\n",
    "            (df_means['dist_rhypo'] == rhypo)]\n",
    "        if df_trace.size == 0:\n",
    "            print 'No data found for', trace_label\n",
    "            continue\n",
    "            \n",
    "        series = df_trace.drop(extra_cols, axis=1).sort(axis=1).iloc[0,:]\n",
    "            \n",
    "        trace_label = '%s %g km' % (gmpe_key, rhypo)\n",
    "        h = ax.loglog(series.index, series.values,\n",
    "                      label=trace_label, alpha=0.5)\n",
    "\n",
    "        digitized_file = digitized_template % (mags[0], rhypo, gmpe_key)\n",
    "        if os.path.exists(digitized_file):\n",
    "            data = np.genfromtxt(digitized_file, delimiter=',')\n",
    "            data = data[data[:,0].argsort()]\n",
    "            ax.plot(data[:,0], data[:,1],\n",
    "                    color=h[0].get_color(), marker='x', \n",
    "                    linestyle='none', alpha=0.5)\n",
    "            \n",
    "            df_trace.is_copy = False\n",
    "            \n",
    "            df_trace[T] = np.interp(T, data[:,0], data[:,1]).round(5)\n",
    "            if empty:\n",
    "                df_interp = df_trace\n",
    "                empty = False\n",
    "            else:\n",
    "                df_interp = pd.concat((df_interp, df_trace), ignore_index=True)\n",
    "        else:\n",
    "            print '%s not available' % digitized_file\n",
    "                \n",
    "ax.grid(which='both')\n",
    "ax.set_xlim((min(T), max(T)))\n",
    "ax.set_xlabel('Period [s]')\n",
    "ax.set_ylabel('SA($\\\\xi$=%g%%) [g]' % im_types[0].damping)\n",
    "ax.legend(loc='lower left', labelspacing=0.3, fontsize=10)\n",
    "plt.savefig('Figure_3_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate data for bedrock motion Figure 5\n",
    "mags = [6.5]\n",
    "rakes = [0] # degrees\n",
    "distances = [35.] # km\n",
    "vs30s = [4000., 2000., 1000., 500., 250.] # m/s\n",
    "im_types = sorted(gmpes[0].COEFFS_BEDROCK.sa_coeffs.keys())\n",
    "\n",
    "df_means = gt.compute_gmpe(gmpes[0], mags, rakes, distances, vs30s, im_types)[0]\n",
    "df_means['gmpe'] = regions_short[0]\n",
    "\n",
    "df_stddevs2 = gt.compute_gmpe(gmpes[0], mags, rakes, distances, vs30s, im_types)[1]\n",
    "df_stddevs2['gmpe'] = regions_short[0]\n",
    "df_stddevs = pd.concat((df_stddevs, df_stddevs2))\n",
    "df_stddevs = gt.df_massage(df_stddevs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stddevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produce Figure 5\n",
    "digitized_template = 'Digitized/Class_%s.csv'\n",
    "\n",
    "vs30s = sorted(list(set(df_means['site_vs30'])), reverse=True)\n",
    "sctx = gsim.base.SitesContext()\n",
    "sctx.vs30 = np.array(vs30s)\n",
    "site_classes = gmpe.get_nehrp_classes(sctx)\n",
    "site_classes[gmpe.is_bedrock(sctx)] = 'bedrock'\n",
    "\n",
    "numeric_cols = np.array([tb.is_numeric(item) for item in df_means.columns])\n",
    "extra_cols = df_means.columns[~numeric_cols]\n",
    "T = [float(item) for item in df_means.columns[numeric_cols]]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for vs30, site_class in zip(vs30s, site_classes):\n",
    "                \n",
    "    df_trace = df_means[df_means['site_vs30'] == vs30]\n",
    "    if df_trace.size == 0:\n",
    "        print 'No data found for', trace_label\n",
    "        continue\n",
    "        \n",
    "    series = df_trace.drop(extra_cols, axis=1).sort(axis=1).iloc[0,:]\n",
    "\n",
    "    h = ax.loglog(series.index, series.values,\n",
    "                  label=site_class, alpha=0.5)\n",
    "\n",
    "    digitized_file = digitized_template % site_class\n",
    "    if os.path.exists(digitized_file):\n",
    "        data = np.genfromtxt(digitized_file, delimiter=',')\n",
    "        data = data[data[:,0].argsort()]\n",
    "        ax.plot(data[:,0], data[:,1],\n",
    "                color=h[0].get_color(), marker='x', \n",
    "                linestyle='none', alpha=0.5)\n",
    "\n",
    "        df_trace.is_copy = False\n",
    "        df_trace[T] = np.interp(T, data[:,0], data[:,1], right=np.nan).round(5)\n",
    "        df_interp = pd.concat((df_interp, df_trace), ignore_index=True)\n",
    "    else:\n",
    "        print '%s not available' % digitized_file\n",
    "                \n",
    "#ax.autoscale(enable=True, tight=True)\n",
    "ax.grid(which='both')\n",
    "ax.set_xlim((min(T), max(T)))\n",
    "ax.set_xlabel('Period [s]')\n",
    "ax.set_ylabel('SA($\\\\xi$=%g%%) [g]' % im_types[0].damping)\n",
    "ax.legend(loc='lower left', labelspacing=0.3, fontsize=10)\n",
    "plt.savefig('Figure_5_computed.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_interp = gt.df_massage(df_interp)\n",
    "df_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check that warning is raised for low VS30\n",
    "rctx = gsim.base.RuptureContext()\n",
    "sctx = gsim.base.SitesContext()\n",
    "dctx = gsim.base.DistancesContext()\n",
    "\n",
    "rctx.mag = np.array([6.])\n",
    "rctx.rake = np.array([-90.])\n",
    "dctx.rhypo = np.array([100.])\n",
    "sctx.vs30 = np.array([10.])\n",
    "uncertainty_types = list(gmpe.DEFINED_FOR_STANDARD_DEVIATION_TYPES)\n",
    "\n",
    "with warnings.catch_warnings(record=True) as w:\n",
    "    # Cause all warnings to always be triggered.\n",
    "    warnings.simplefilter('always')\n",
    "    # Trigger a warning.\n",
    "    mean, [stddev] = gmpe.get_mean_and_stddevs(\n",
    "        sctx, rctx, dctx, im_types[0], uncertainty_types)\n",
    "    # Verify some things\n",
    "    assert len(w) == 1\n",
    "    assert issubclass(w[-1].category, UserWarning)\n",
    "    assert 'not supported' in str(w[-1].message).lower()\n",
    "    assert np.all(np.isnan(mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# produce result files for unittest\n",
    "test_path = '/home/nick/src/python/GEM/oq-hazardlib/openquake/hazardlib/tests/gsim/data/%s/' \\\n",
    "    % gmpe_short\n",
    "\n",
    "means_files = [os.path.join(test_path, '%s_%s_MEAN.csv' \n",
    "                            % (gmpe_short, region_short))\n",
    "               for region_short in regions_short]\n",
    "for means_file, region_short in zip(means_files, regions_short):\n",
    "    indices = df_interp['gmpe'] == region_short\n",
    "    df_subset = df_interp[indices].drop(['rup_rake','gmpe'], axis=1).copy()\n",
    "    df_subset = gt.df_massage(df_subset)\n",
    "    df_subset.to_csv(means_file, index=False)\n",
    "    \n",
    "stddev_files = [os.path.join(test_path, '%s_%s_STD_TOTAL.csv' \n",
    "                            % (gmpe_short, region_short))\n",
    "               for region_short in regions_short]\n",
    "\n",
    "for stddev_file, region_short in zip(stddev_files, regions_short):\n",
    "    indices = df_stddevs['gmpe'] == region_short\n",
    "    df_subset = df_stddevs[indices].drop(['rup_rake','gmpe'], axis=1).copy()\n",
    "    df_subset = gt.df_massage(df_subset)\n",
    "    df_subset.to_csv(stddev_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run through unittests\n",
    "threshhold = 0.015\n",
    "\n",
    "fig, axes = plt.subplots(len(gmpes), 1, figsize=(6,12), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.05)\n",
    "\n",
    "for ax, gmpe, means_file in zip(axes, gmpes, means_files):\n",
    "    gmpe_name = gmpe.__class__.__name__\n",
    "    ax.add_artist(AnchoredText(gmpe_name, loc=1, frameon=False))\n",
    "\n",
    "    df_ref = gt.df_massage(pd.read_csv(means_file))\n",
    "\n",
    "    mags = np.sort(np.array(list(set(df_ref['rup_mag']))))\n",
    "    rakes = 0\n",
    "    distances = sorted(list(set(df_ref['dist_rhypo'])))\n",
    "    vs30s = np.sort(np.array(list(set(df_ref['site_vs30']))))\n",
    "    sa_cols = np.array([tb.is_numeric(item) for item in df_ref.columns])\n",
    "    imt_cols = np.array([gt.is_imt(item) for item in df_ref.columns])\n",
    "    im_types = [gt.get_imt(item) for item in df_ref.columns[imt_cols]]\n",
    "\n",
    "    df_new = gt.compute_gmpe(gmpe, mags, rakes, distances, vs30s, im_types)[0]\n",
    "    df_new = df_new[df_ref.columns]\n",
    "\n",
    "    for vs30 in vs30s:\n",
    "        for dist in distances:\n",
    "            trace_label = 'rhypo=%g km, vs30=%g m/s' % (dist, vs30)\n",
    "\n",
    "            df_trace = df_ref[\n",
    "                (df_ref['dist_rhypo'] == dist) & \n",
    "                (df_ref['site_vs30'] == vs30)]\n",
    "            if df_trace.size == 0:\n",
    "                continue\n",
    "            ref = df_trace[df_ref.columns[sa_cols]]\n",
    "            \n",
    "            df_trace = df_new[\n",
    "                (df_new['dist_rhypo'] == dist) & \n",
    "                (df_new['site_vs30'] == vs30)]\n",
    "            new = df_trace[df_ref.columns[sa_cols]]\n",
    "            \n",
    "            h = ax.loglog(new.columns.values, new.values.reshape((-1,)), \n",
    "                          label=trace_label, alpha=0.5)\n",
    "\n",
    "            ax.loglog(ref.columns.values, ref.values.reshape((-1,)), \n",
    "                      linestyle='none', marker='x', \n",
    "                     color=h[0].get_color(), alpha=0.5)\n",
    "            \n",
    "\n",
    "    ne_stacked = (tb.df_compare(df_new, df_ref) > threshhold).stack()\n",
    "    changed = ne_stacked[ne_stacked]\n",
    "    changed.index.names = ['index', 'column']\n",
    "\n",
    "    difference_locations = np.where(\n",
    "        tb.df_compare(df_new, df_ref) > threshhold)\n",
    "    changed_from = df_new.values[difference_locations]\n",
    "    changed_to = df_ref.values[difference_locations]\n",
    "    summary = pd.DataFrame({'from': changed_from, \n",
    "                            'percent': 100*(changed_from/changed_to - 1)}, \n",
    "                           index=changed.index)\n",
    "    if summary.size > 0:\n",
    "        print\n",
    "        print gmpe.__class__.__name__\n",
    "        display(summary)\n",
    "                \n",
    "for ax in axes:\n",
    "    ax.grid(which='both')\n",
    "    ax.set_xlim((0.01, 4))\n",
    "    ax.set_ylim((0.003, 1))\n",
    "    ax.set_ylabel('SA($\\\\xi$=%g%%) [m/s$^2$]' % (im_types[0].damping))\n",
    "    ax.legend(loc='lower left', labelspacing=0, fontsize=10)\n",
    "axes[-1].set_xlabel('Period [s]')\n",
    "\n",
    "plt.savefig('Unit_Test_Summary.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('Unit_Test_Summary.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
